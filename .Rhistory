grid.arrange(arrangeGrob(p1,p2, ncol = 2),
heights=c(3.5/4, 3.5/4), ncol=1,
p3,nrow=2, top=textGrob("Diagnosed with a mental health issues",gp=gpar(cex=1.5,col="black")))
rm(df.2017)
df.full<-bind_rows(df.2014, df.2016)
table(df.full$fam_history_MI)
##Gender
chisq.test(table(df.full$diagnose, df.full$gender))
##Family history
chisq.test(table(df.full$diagnose, df.full$fam_history_MI))
chisq.test(table(df.full$diagnose, df.full$location))
chisq.test(table(df.full$diagnose, df.full$remote_wrk))
#remote work is still independent. Remove
df.full$remote_wrk<-NULL
res <- wilcox.test(age ~ diagnose, data = df.full,
exact = FALSE)
res
#Wilxcon test to see if there is a significant difference in Age between people disgnosed with mental health issues.
wilcox.test(age ~ diagnose, data = df.full,
exact = FALSE)
shapiro.test(df.full$age)
#We can remove the year column and recode the diagnose column
df.full$year<-NULL
df.full<-df.full%>%
mutate(diagnose=ifelse(diagnose=="Yes",1,0))
df.full$diagnose<-as.factor(df.full$diagnose)
table(df.full$diagnose)
table(df.2014$diagnose)
table(df.2016$diagnose)
df.full%>%ggplot(aes(x=diagnose, y=age))+
geom_boxplot()+
theme_bw()
summary(df.full$age)
df.full%>%ggplot(aes(x=diagnose, y=age))+
geom_boxplot()+
theme_bw()
df.full<-df.full%>%
filter(age<100)
#Test normality of age
shapiro.test(df.full$age)
#Wilcox test to see if there is a significant difference in Age between people disgnosed with mental health issues.
wilcox.test(age ~ diagnose, data = df.full,
exact = FALSE)
df.full%>%ggplot(aes(x=diagnose, y=age))+
geom_boxplot()+
theme_bw()
df.full<-df.full%>%
filter(age<100 & age>0)
#Test normality of age
shapiro.test(df.full$age)
#Wilcox test to see if there is a significant difference in Age between people disgnosed with mental health issues.
wilcox.test(age ~ diagnose, data = df.full,
exact = FALSE)
df.full%>%ggplot(aes(x=diagnose, y=age))+
geom_boxplot()+
theme_bw()
summary(df.full$age)
df.full%>%ggplot(aes(x=diagnose, y=age))+
geom_boxplot()+
theme_bw()
df.full<-df.full%>%
filter(age<100 & age>16)
#Test normality of age
shapiro.test(df.full$age)
#Wilcox test to see if there is a significant difference in Age between people disgnosed with mental health issues.
wilcox.test(age ~ diagnose, data = df.full,
exact = FALSE)
df.full%>%ggplot(aes(x=diagnose, y=age))+
geom_boxplot()+
theme_bw()
summary(df.full$age)
df.full%>%ggplot(aes(x=diagnose, y=age, fill=diagnose))+
geom_boxplot()+
theme_bw()
df.full%>%ggplot(aes(x=diagnose, y=age, fill=diagnose))+
geom_boxplot()+
theme_bw()+
theme(legend.position = "none")
#split data
set.seed(4)
index<- createDataPartition(df.full$diagnose,p=0.8,list=FALSE)
library(caret)
#split data
set.seed(4)
index<- createDataPartition(df.full$diagnose,p=0.8,list=FALSE)
training<- df.full[index,]
testing<- df.full[-index,]
rm(df.2014,df.2016)
round(prop.table(table(df.full$diagnose)),3)
round(prop.table(table(training$diagnose)),3)
round(prop.table(table(testing$diagnose)),3)
## Train the model
logit.mod <- glm(diagnose~., family = binomial(link = 'logit'),
data = training)
## Look at the result
summary(logit.mod)
## Predict the mental health against our test data
logit.pred.prob <- predict(logit.mod, testing, type = 'response')
logit.pred <- as.factor(ifelse(logit.pred.prob > 0.5, 1, 0))
head(testing, 3)
head(logit.pred.prob, 3)
head(testing, 3)
logit.pred <- as.factor(ifelse(logit.pred.prob > 0.5, 1, 0))
logit.pred
head(testing, 3)
head(logit.pred, 3)
head(testing, 3)
confusionMatrix(data = logit.pred, testing$diagnose,
positive = "1")
log.result <- confusionMatrix(data = logit.pred, testing$diagnose,
positive = "1")
log.precision <- log.result$byClass['Pos Pred Value']
log.recall    <- log.result$byClass['Sensitivity']
log.F1        <- log.result$byClass['F1']
#Feature analysis
anova(logit.mod, test="Chisq")
#Odd ratio
exp(cbind(coef(logit.mod), confint.default(logit.mod)))
#Decision Tree
# Train model
tree.model <- rpart(diagnose ~ .,
data = training,
method = "class",
control = rpart.control(xval = 10))
# Plot
rpart.plot(tree.model)
#Decision Tree
# Train model
tree.model <- rpart(diagnose ~ .,
data = training,
method = "class",
control = rpart.control(xval = 100))
# Plot
rpart.plot(tree.model)
#Decision Tree
# Train model
tree.model <- rpart(diagnose ~ .,
data = training,
method = "class",
control = rpart.control(xval = 10))
# Plot
rpart.plot(tree.model)
#Decision Tree
# Train model
tree.model <- rpart(diagnose~.,
data = training,
method = "class",
control = rpart.control(xval = 10))
# Plot
rpart.plot(tree.model)
predict(tree.model, newdata = testing, type = "class")
confusionMatrix(data = tree.pred, testing$diagnose)
# Evaluation metrics (Tree)
tree.pred      <- predict(tree.model, newdata = testing, type = "class")
confusionMatrix(data = tree.pred, testing$diagnose)
tree.pred      <- predict(tree.model, newdata = testing, type = "class")
tree.result    <- confusionMatrix(data = tree.pred, testing$diagnose)
tree.precision <- tree.result$byClass['Pos Pred Value']
tree.recall    <- tree.result$byClass['Sensitivity']
tree.F1        <- tree.result$byClass['F1']
#Random Forest
#Train model
forest.model <- randomForest(diagnose~.,
data = training,
ntree=200,
type="classification")
# See error reduction with number of trees ( not much gained beyond ~25 trees)
plot(forest.model)
forest.model
# See error reduction with number of trees (not much gained beyond ~150 trees)
plot(forest.model)
# Look at the variable Importance from the random forest
varImpPlot(forest.model, sort = T, main="Variable Importance")
## Look at the result
summary(logit.mod)
# Look at the variable Importance from the random forest
varImpPlot(forest.model, sort = T, main="Variable Importance")
# Evaluation metrics
forest.pred      <- predict(forest.model, newdata = testing, type = "class")
confusionMatrix(data = forest.pred, testing$diagnose)
# Evaluation metrics
forest.pred      <- predict(forest.model, newdata = testing, type = "class")
forest.result    <- confusionMatrix(data = forest.pred, testing$diagnose)
forest.precision <- forest.result$byClass['Pos Pred Value']
forest.recall    <- forest.result$byClass['Sensitivity']
forest.F1        <- forest.result$byClass['F1']
log.precision
tree.precision
forest.precision
log.recall
tree.recall
forest.recall
confusionMatrix(data = forest.pred, testing$diagnose)
#Precision
log.precision
tree.precision
forest.precision
#Recall
log.recall
tree.recall
forest.recall
#F1 Score
log.F1
tree.F1
forest.F1
logit.mod
## Look at the result
summary(logit.mod)
library(tidyverse)
library(DBI)
library(RSQLite)
library(ggplot2)
library(plotly)
library(lubridate)
library(ggcorrplot)
library(DataExplorer)
library(gridExtra)
library(lattice)
library(grid)
library(lme4)
library(smotefamily)
library(InformationValue)
library(ROCR)
library(rpart)
library(randomForest)
library(xgboost)
library(MASS)
library(ggmosaic)
library(e1071)
library(ranger)
library(penalized)
library(rpart.plot)
library(ggcorrplot)
library(caret)
library(caTools)
library(doParallel)
library(readxl)
library(oddsratio)
library(partykit)
library(jtools)
library(kableExtra)
library(knitr)
registerDoParallel(cores=4)
conn<-dbConnect(SQLite(), "mental_health.sqlite")
tables <- dbListTables(conn)
#Pivot the columns longer and rename them
df.2014<-df.2014%>%
pivot_wider(names_from = question,
values_from = answer)
df.2014<-df.2014%>%
rename(age=`What is your age?`,
location=`What country do you live in?`,
gender=`What is your gender?`,
fam_history_MI=`Do you have a family history of mental illness?`,
diagnose=`Have you ever sought treatment for a mental health disorder from a mental health professional?`,
remote_wrk=`Do you work remotely (outside of an office) at least 50% of the time?`,
id=UserID)
df.2016<-df.2016%>%
pivot_wider(names_from = question,
values_from = answer)
df.2016<-df.2016%>%
rename(age=`What is your age?`,
location=`What country do you live in?`,
gender=`What is your gender?`,
fam_history_MI=`Do you have a family history of mental illness?`,
diagnose=`Have you ever been diagnosed with a mental health disorder?`,
remote_wrk=`Do you work remotely?`,
id=UserID,
position=`Which of the following best describes your work position?`)
df.2017<-df.2017%>%
pivot_wider(names_from = question,
values_from = answer)
df.2017<-df.2017%>%
rename(age=`What is your age?`,
location=`What country do you live in?`,
gender=`What is your gender?`,
fam_history_MI=`Do you have a family history of mental illness?`,
diagnose= `Are you openly identified at work as a person with a mental health issue?`,
race=`What is your race?`,
id=UserID)
# 2014 dataset
# For consistency purposes, only keep those that identified as Male or Female
# Keep only locations with more than 20 observations in each of the survey years
country<-c("Australia", "Canada", "Germany", "Netherlands",
"United Kingdom", "United States")
#Transform categorical variables
df.2014<-df.2014%>%
filter(location %in% country)%>%
mutate(gender=as.factor(gender),
diagnose=as.factor(diagnose),
fam_history_MI=as.factor(fam_history_MI),
remote_wrk=as.factor(remote_wrk),
location=as.factor(location))%>%
filter(gender=="Male"|gender=="Female")%>%
mutate(diagnose= ifelse(diagnose==1, "Yes", "No"))
df.2014$id<-NULL
df.2014$age<-parse_number(df.2014$age)
# 2016 dataset
# Some of the columns are lists, unlist them
df.2016$age<-unlist(df.2016$age)
df.2016$gender<-unlist(df.2016$gender)
df.2016$location<-unlist(df.2016$location)
df.2016$fam_history_MI<-unlist(df.2016$fam_history_MI)
df.2016$diagnose<-unlist(df.2016$diagnose)
df.2016$remote_wrk<-unlist(df.2016$remote_wrk)
#Create country variable to match list of countries
country<-c("Australia", "Canada", "Germany", "Netherlands",
"United Kingdom", "United States of America")
df.2016<-df.2016 %>%
filter(gender=="Male"|gender=="Female")%>%
filter(location %in% country)%>%
mutate(location=ifelse(location=="United States of America",
"United States", location))%>%
mutate(gender=as.factor(gender),
diagnose=as.factor(diagnose),
fam_history_MI=as.factor(fam_history_MI),
remote_wrk=as.factor(remote_wrk),
location=as.factor(location))
df.2016$position<-NULL
df.2016$id<-NULL
df.2016$age<-parse_number(df.2016$age)
# 2017 dataset
# This dataset has a Race column but it needs recoding
df.2017<-df.2017 %>%
filter(gender=="Male"|gender=="Female")%>%
filter(location %in% country)%>%
mutate(race=ifelse(race=="-1", "Unidentified",
ifelse(race=="More than one of the above", "Multiracial",
ifelse(race=="I prefer not to answer", "Unidentified", race))))%>%
mutate(diagnose= ifelse(diagnose==1, "Yes", "No"))%>%
mutate(gender=as.factor(gender),
diagnose=as.factor(diagnose),
fam_history_MI=as.factor(fam_history_MI),
location=as.factor(location),
race=as.factor(race))
df.2017$id<-NULL
df.2017$age<-parse_number(df.2017$age)
#Explore data after cleaning
plot_intro(df.2014, ggtheme = theme_bw())
plot_bar(df.2014, maxcat = 5, by="gender",
ggtheme = theme_bw(), ncol = 2,
title = "2014 Respondents")
plot_bar(df.2016, maxcat = 5, by="gender",
ggtheme = theme_bw(), ncol = 2,
title = "2016 Respondents")
plot_bar(df.2017, maxcat = 5, by="gender",
ggtheme = theme_bw(), ncol = 2,
title = "2017 Respondents")
#2014
chi.square <- vector()
p.value <- vector()
cateVar <- df.2014 %>%
dplyr::select(-diagnose) %>%
keep(is.factor)
for (i in 1:length(cateVar)) {
p.value[i] <- round(chisq.test(df.2014$diagnose, unname(unlist(cateVar[i])), correct = FALSE)[3]$p.value, 3)
chi.square[i] <- unname(chisq.test(df.2014$diagnose, unname(unlist(cateVar[i])), correct = FALSE)[1]$statistic)
}
chi_sqaure_test <- tibble(variable = names(cateVar)) %>%
add_column(chi.square = chi.square) %>%
add_column(p.value = p.value)
knitr::kable(chi_sqaure_test, caption = "Chi-square Test (2014)")%>%
kable_styling()
#2016
chi.square <- vector()
p.value <- vector()
cateVar <- df.2016 %>%
dplyr::select(-diagnose) %>%
keep(is.factor)
for (i in 1:length(cateVar)) {
p.value[i] <- round(chisq.test(df.2016$diagnose, unname(unlist(cateVar[i])), correct = FALSE)[3]$p.value, 3)
chi.square[i] <- unname(chisq.test(df.2016$diagnose, unname(unlist(cateVar[i])), correct = FALSE)[1]$statistic)
}
chi_sqaure_test <- tibble(variable = names(cateVar)) %>%
add_column(chi.square = chi.square) %>%
add_column(p.value = p.value)
knitr::kable(chi_sqaure_test, caption = "Chi-square Test (2016)")%>%
kable_styling()
#2017
chi.square <- vector()
p.value <- vector()
cateVar <- df.2017 %>%
dplyr::select(-diagnose) %>%
keep(is.factor)
for (i in 1:length(cateVar)) {
p.value[i] <- round(chisq.test(df.2017$diagnose, unname(unlist(cateVar[i])), correct = FALSE)[3]$p.value, 3)
chi.square[i] <- unname(chisq.test(df.2017$diagnose, unname(unlist(cateVar[i])), correct = FALSE)[1]$statistic)
}
chi_sqaure_test <- tibble(variable = names(cateVar)) %>%
add_column(chi.square = chi.square) %>%
add_column(p.value = p.value)
knitr::kable(chi_sqaure_test, caption = "Chi-square Test (2017)")%>%
kable_styling()
round(prop.table(table(df.2014$diagnose)),3)
round(prop.table(table(df.2014$diagnose)),3)
round(prop.table(table(df.2016$diagnose)),3)
round(prop.table(table(df.2017$diagnose)),3)
summary(df.2016$age)
#There are some impossible values in the age column. Remove them
df.2016<-df.2016%>%
filter(age<100 & age>16)
round(prop.table(table(df.2014$diagnose)),3)
round(prop.table(table(df.2016$diagnose)),3)
round(prop.table(table(df.2017$diagnose)),3)
rm(df.2014, df.2017)
df.2016$remote_wrk<-NULL
#Test normality of age
shapiro.test(df.2016$age)
#Wilcox test to see if there is a significant difference in Age between people diagnosed with mental health issues.
wilcox.test(age ~ diagnose, data = df.2016,
exact = FALSE)
df.2016%>%ggplot(aes(x=diagnose, y=age, fill=diagnose))+
geom_boxplot()+
theme_bw()+
theme(legend.position = "none")
#Wilcox test to see if there is a significant difference in Age between people diagnosed with mental health issues.
wilcox.test(age ~ diagnose, data = df.2016,
exact = FALSE)
#Test normality of age
shapiro.test(df.2016$age)
#Wilcox test to see if there is a significant difference in Age between people diagnosed with mental health issues.
wilcox.test(age ~ diagnose, data = df.2016,
exact = FALSE)
df.2016%>%ggplot(aes(x=diagnose, y=age, fill=diagnose))+
geom_boxplot()+
theme_bw()+
theme(legend.position = "none")
#We can remove the year column and recode the diagnose column
df.2016$year<-NULL
df.2016<-df.2016%>%
mutate(diagnose=ifelse(diagnose=="Yes",1,0))
df.2016$diagnose<-as.factor(df.2016$diagnose)
#split data
set.seed(4)
index<- createDataPartition(df.2016$diagnose,p=0.8,list=FALSE)
training<- df.2016[index,]
testing<- df.2016[-index,]
#Check split
round(prop.table(table(df.2016$diagnose)),3)
round(prop.table(table(training$diagnose)),3)
round(prop.table(table(testing$diagnose)),3)
## Train the model
logit.mod <- glm(diagnose~., family = binomial(link = 'logit'),
data = training)
## Look at the result
summ(logit.mod)
## Predict the mental health against our test data
logit.pred.prob <- predict(logit.mod, testing, type = 'response')
logit.pred <- as.factor(ifelse(logit.pred.prob > 0.5, 1, 0))
head(testing, 3)
head(logit.pred, 3)
#Feature analysis
knitr::kable(anova(logit.mod, test="Chisq"))
#Odd ratio
knitr::kable(exp(cbind(coef(logit.mod), confint.default(logit.mod))))
# Evaluation Metrics
log.result <- confusionMatrix(data = logit.pred, testing$diagnose,
positive = "1")
log.precision <- log.result$byClass['Pos Pred Value']
log.recall    <- log.result$byClass['Sensitivity']
log.F1        <- log.result$byClass['F1']
summ(log.result)
#Odd ratio
knitr::kable(round(exp(cbind(coef(logit.mod), confint.default(logit.mod)))),3)
#Odd ratio
knitr::kable(round(exp(cbind(coef(logit.mod), confint.default(logit.mod))),3))
#Feature analysis
knitr::kable(round(anova(logit.mod, test="Chisq")),3)
#Feature analysis
knitr::kable(round(anova(logit.mod, test="Chisq"),3))
log.result
#Decision Tree
# Train model
tree.model <- rpart(diagnose~.,
data = training,
method = "class",
control = rpart.control(xval = 10))
# Plot
rpart.plot(tree.model)
# Evaluation metrics (Tree)
tree.pred      <- predict(tree.model, newdata = testing, type = "class")
tree.result    <- confusionMatrix(data = tree.pred, testing$diagnose)
tree.precision <- tree.result$byClass['Pos Pred Value']
tree.recall    <- tree.result$byClass['Sensitivity']
tree.F1        <- tree.result$byClass['F1']
tree.pred
tree.result
tree.model
tree.result
#Random Forest
#Train model
forest.model <- randomForest(diagnose~.,
data = training,
ntree=200,
type="classification")
# See error reduction with number of trees (not much gained beyond ~150 trees)
plot(forest.model)
# Look at the variable Importance from the random forest
varImpPlot(forest.model, sort = T, main="Variable Importance")
# Evaluation metrics
forest.pred      <- predict(forest.model, newdata = testing, type = "class")
forest.result    <- confusionMatrix(data = forest.pred, testing$diagnose)
forest.precision <- forest.result$byClass['Pos Pred Value']
forest.recall    <- forest.result$byClass['Sensitivity']
forest.F1        <- forest.result$byClass['F1']
forest.result
# Look at the variable Importance from the random forest
varImpPlot(forest.model, sort = T, main="Variable Importance")
#Feature analysis
knitr::kable(round(anova(logit.mod, test="Chisq"),3),
caption = "Likelihood Ratio test")%>%
kable_styling()
